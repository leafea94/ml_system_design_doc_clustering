# **ML System Design – сервис кластеризации магазинов**
*Шаблон ML System Design Doc от телеграм-канала [Reliable ML](https://t.me/reliable_ml)*
- Рекомендации по процессу заполнения документа (workflow) - [здесь](https://github.com/IrinaGoloshchapova/ml_system_design_doc_ru/blob/main/ML_System_Design_Doc_Workflow.md).
- Детальный доклад о том, что такое ML System Design Doc и о том, как, когда и зачем его составлять - [тут](https://www.youtube.com/watch?v=PW9TGNr1Vqk).


## **1. Цели и предпосылки**
### **1.1. Зачем идем в разработку продукта?**
**Бизнес-цель:** Помощь бизнесу в быстром принятии решений с помощью инструмента для автоматической группировки магазинов по базовым метрикам, важным для ритейла, включая гео-факторы. 
Одна из типовых задач, в которых может помочь инструмент - адаптация CVP (Customer Value Proposition) с учетом кластеров.

**Почему станет лучше, чем сейчас, от использования ML:** Автоматизация ручного подбора кластеров, уменьшение трудозатрат и времени, появление воспроизводимости расчетов, повышение качества кластеризации (применение математических алгоритмов).
Бизнес проводит ручную кластеризацию, основываясь, в основном, на малом количестве факторов, таких как: география расположения ТК, формат, продажи. При этом не учитываются многие параметры, которые значительно могут повлиять на более точное разбиение ТК по кластерам.

**Что будем считать успехом итерации с точки зрения бизнеса:** Работающий сервис кластеризации ТК и предоставление готового отчёта
 
### **1.2. Бизнес-требования и ограничения**
**Целевое решение:** сервис для кластеризации ТК

**Логика работы:**
- Поступает запрос от пользователя на получение кластеризации выбранных ТК
- Сервис обращается к таблицам с предраcчитанными данными по продажам, а также к таблицам с геофичами и данными по магазинам (дата открытия и т.д.), выкачивает данные, агрегирует их и запускает алгоритм кластеризации. 
- Предварительно по договоренности с бизнесом планируется, что витрина с данными будет обновляться раз в квартал.

**Бизнес-ограничения:**

- Кластеризация должна быть гибко настраиваемой – могут использоваться как все параметры, так и должна присутствовать возможность выбора наиболее релевантных для бизнеса показателей (например, исключительно аналитические/коммерческие показатели)
- Есть ряд дефолтных параметров, которые всегда должны присутствовать при кластеризации и по которым должны выводиться метрики в отчет
- Кластеризация проводится для магазинов формата Гипермаркет 
- Возможность выбирать количество кластеров руками, так и получать автоматически разбиение на оптимальное количество кластеров 
- Скорость получения готового отчета (требуется производить расчёты и выгружать отчет «на лету»)

**Критерии успеха и возможные пути развития проекта:** критерием успеха служит позитивная обратная связь пользователей на разработанный инструмент кластеризации и уменьшение трудозатрат на ручной расчёт.

Сейчас бизнес тратит на кластеризацию от 3-5 часов чистого времени (+ожидание от других команд и задействование их ресурсов для выгрузки данных из различных сервисов и аналитических отчетов).
С инструментом кластеризации прогнозируется, что будет уходить до 15 минут на аналогичный расчёт (до 20 минут если требуются объяснения как пользоваться сервисом). 

Учитывая, что кластеризацию делают несколько раз в неделю (обычно около 3 = 12 в месяц) и при допущении, что этим занимается один сотрудник/один отдел, то минимальная экономия времени получается 33 часа в неделю или 132 часа в месяц -> в пересчёте на ФОТ около 1 млн рублей в год. 

**Возможные пути развития проекта:** 
- Проводить кластеризацию для разных типов объектов торговой сети
- Усиление алгоритма кластеризации
- Разработка фронта, т.к. стримлит хорошо подходит для быстрого построения прототипа, но не для долгосрочной перспективы (но это должно быть оправдано эффектом от проекта)
 
### **1.3. Что входит в скоуп проекта/итерации, что не входит**
**На закрытие каких БТ подписываемся в данной итерации:** Сбор информации от заказчиков (уточнение признаков, метрик), подготовка данных, проверка их достаточности, определение алгоритма кластеризации и построение дашборда в streamlit с возможностью выгрузки отчета.

**Результат с точки зрения качества кода и воспроизводимости решения:**
Отдельный репозиторий с приложением streamlit. Используется модульный подход, где каждый модуль отвечает за свою часть – предобработка данных, кластеризация, запуск приложения и т.д.

**Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации):** Добавить логирование, авторизацию пользователей
 
### **1.4 Предпосылки решения**
**Проблема:**
В настоящий момент уходит много времени на ручное разбиение ТК на кластеры, и для уменьшения трудозатрат бизнесу необходим удобный и простой в использовании сервис.
Так, например, бизнес-заказчикам требуется оперативно проводить кластеризацию магазинов для того, чтобы понимать, следует ли вносить изменения в текущую модель CVP (Customer Value Proposition). 

**Зачем нужен сервис (пример использования):**
Нужно понять, в чём различия ТК на приемлемом уровне управляемости (т.е. на уровне кластера) для того, чтобы определить, как подстраивать CVP (Customer Value Proposition) под каждый из кластеров. 
 
## **2. Методология**

### **2.1. Постановка задачи**
- Алгоритм кластеризации для разных типов ТК
- Разработать продовый сервис для кластеризации

Финальный результат модели - предоставление готового сервиса для расчёта кластеризации ТК
 
### **2.2. Схема решения** 
![alt-текст](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "Текст заголовка логотипа 1")

### **2.3. Этапы решения**
 
#### **Этап 0. Сбор и уточнение требований к кластеризации и сервису.**
Признаки, входные данные, их формат, технические и формальные требования. 
 
#### **Этап 1. Анализ и подготовка имеющихся данных и атрибутов для кластеризации из БТ**

 
#### **Этап 2. Подготовка датасета**
Подготовка единого датасета с имеющимися атрибутами. Проверка корректности данных в используемых атрибутах. 
 
#### **Этап 3. Алгоритм кластеризации**
Тестирование различных широко распространенных алгоритмов кластеризации, использование уже имеющихся наработок внутри отдела. 

*Базово планируется использовать алгоритм AgglomerativeClustering из библиотеки sklearn, т.к. на данный момент он кажется наиболее оптимальным, поскольку он довольно прост, но при этом хорошо работает, когда надо кластеризовать небольшие объемы данных (в нашем случае - небольшое количество ТК)

**Пайплайн работы алгоритма:**
- Готовим данные - по строчкам находятся наблюдения, колонки - фичи. 
- Заполнение пропуска в данных медианным значением
- Приведение данных к стандартизированному виду
- Уменьшение размерности до n компонент. 
- Количество компонент будем отбирать динамично на основе критерия Кайзера (считаем, что компонента весомая и ее стоит оставлять, если ее собственное значение >= 1).
- Применение непосредственно самого алгоритма кластеризации

Для оценки  кластеризации бизнесом будем использовать расстояние между кластерами, отображенное по оси y на графике дендрограммы и средние значения по кластеру по заданным параметрам (выводятся в эксель-отчете).
Средние значения выводятся по ряду дефолтных параметров (например, количество покупателей), и показывают, различаются ли кластера между собой: если кластеризация выполнена хорошо, то средние показатели у кластеров должны быть различны.

Также в качестве технических метрик адекватности кластеризации будем смотреть на одни из самых используемых мер оценки - индекс Дэвиса-Болдина (DBI), который показывает среднее отношение внутрикластерных разбросов к расстояниям между кластерами (наилучшее разбиение на кластеры минимизирует DBI), и Силуэт, показывающий насколько похож объект на другие объекты из своего кластера в сравнении с объектами из других кластеров. Силуэт принимает значения от -1 до 1: значения, близкие к 1 указывают на то, что объект хорошо вписывается в свой кластер. 
 
#### **Этап 4. Подготовка методологии оценки результатов**
Подготовка методологии для оценки результатов работы выбранного алгоритма кластеризации, а также оценка качества применения кластеризации. 
 
#### **Этап. 5. Подготовка финального отчета**
Подготовка модуля кода для генерации финального excel-отчета по требованиям бизнеса. (Формат отчета будет представлен Product Owner’ом по результатам общения с бизнесом)
 
#### **Этап 6. Подготовка архитектуры и документации сервиса** 
Разработка архитектуры сервиса кластеризации, описание используемых данных, работы алгоритма, кластеров и последующая визуализация.
- **Деплой**

Сервис будет работать в 2-х контурах k8s. dev и prod.

CI dev:
- Tests
- Build
- deploy

Для деплоя в прод необходимо запустить ci по тегу из ветки main.
Данные необходимые для работы приложения скачиваются из dvc перед стартом приложения

**Архитектура:** 
 
![alt-текст](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "Текст заголовка логотипа 1")


#### **Этап 7. Реализация модуля для кластеризации**
Реализация готового модуля с необходимыми для работы алгоритма функциями.
 
#### **Этап 8. Подготовка ETL.**
 Создание скриптов и витрин для обработки входящих данных. Создание DAG-ов расчётов в AirFlow
 
#### **Этап 9. Реализация API сервиса**
Реализация API сервиса выбранной архитектуры, реализация необходимых методов для работы сервиса
Результат - Реализованный докер образ API сервиса 
 
#### **Этап 10. Тестирование**
Проведение процедуры тестирования сервиса в dev-test среде (функциональные и нагрузочные тесты). Предварительно ожидается, что сервисом в текущем виде будут пользоваться до 10 человек несколько раз в сутки. В дальнейшем (если проект будет коммерчески успешен), планируется разработать полноценное приложение с фронтэндом, которое бы выдерживало большую нагрузку. 

#### **Этап 11. Подготовка документации**
Подготовка документации работы алгоритма и сервиса, описание методов API и библиотеки кластеризации
 
#### **Этап 12. Запуск в прод**
Развертка сервиса в продакшн среде и передача на поддержку dev-ops.
